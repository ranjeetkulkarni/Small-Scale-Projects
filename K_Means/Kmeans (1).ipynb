{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "46hVwfLIbJPY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "jyNbLil_b7Cz",
    "outputId": "c00fef1f-5515-4d94-fd1f-c065a795d294"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Univ</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>SAT</th>\n",
       "      <th>Top10</th>\n",
       "      <th>Accept</th>\n",
       "      <th>SFRatio</th>\n",
       "      <th>Expenses</th>\n",
       "      <th>GradRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brown</td>\n",
       "      <td>RI</td>\n",
       "      <td>USA</td>\n",
       "      <td>1310</td>\n",
       "      <td>89</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>22704</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CalTech</td>\n",
       "      <td>CA</td>\n",
       "      <td>USA</td>\n",
       "      <td>1415</td>\n",
       "      <td>100</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>63575</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMU</td>\n",
       "      <td>PA</td>\n",
       "      <td>USA</td>\n",
       "      <td>1260</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>25026</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Columbia</td>\n",
       "      <td>NY</td>\n",
       "      <td>USA</td>\n",
       "      <td>1310</td>\n",
       "      <td>76</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>31510</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cornell</td>\n",
       "      <td>NY</td>\n",
       "      <td>USA</td>\n",
       "      <td>1280</td>\n",
       "      <td>83</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>21864</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dartmouth</td>\n",
       "      <td>NH</td>\n",
       "      <td>USA</td>\n",
       "      <td>1340</td>\n",
       "      <td>89</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>32162</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Duke</td>\n",
       "      <td>NC</td>\n",
       "      <td>USA</td>\n",
       "      <td>1315</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>31585</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Georgetown</td>\n",
       "      <td>DC</td>\n",
       "      <td>USA</td>\n",
       "      <td>1255</td>\n",
       "      <td>74</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>20126</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Harvard</td>\n",
       "      <td>MA</td>\n",
       "      <td>USA</td>\n",
       "      <td>1400</td>\n",
       "      <td>91</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>39525</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JohnsHopkins</td>\n",
       "      <td>MD</td>\n",
       "      <td>USA</td>\n",
       "      <td>1305</td>\n",
       "      <td>75</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>58691</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MIT</td>\n",
       "      <td>MA</td>\n",
       "      <td>USA</td>\n",
       "      <td>1380</td>\n",
       "      <td>94</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>34870</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Northwestern</td>\n",
       "      <td>IL</td>\n",
       "      <td>USA</td>\n",
       "      <td>1260</td>\n",
       "      <td>85</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>28052</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NotreDame</td>\n",
       "      <td>IN</td>\n",
       "      <td>USA</td>\n",
       "      <td>1255</td>\n",
       "      <td>81</td>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>15122</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PennState</td>\n",
       "      <td>PA</td>\n",
       "      <td>USA</td>\n",
       "      <td>1081</td>\n",
       "      <td>38</td>\n",
       "      <td>54</td>\n",
       "      <td>18</td>\n",
       "      <td>10185</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Princeton</td>\n",
       "      <td>NJ</td>\n",
       "      <td>USA</td>\n",
       "      <td>1375</td>\n",
       "      <td>91</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>30220</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Purdue</td>\n",
       "      <td>IN</td>\n",
       "      <td>USA</td>\n",
       "      <td>1005</td>\n",
       "      <td>28</td>\n",
       "      <td>90</td>\n",
       "      <td>19</td>\n",
       "      <td>9066</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stanford</td>\n",
       "      <td>CA</td>\n",
       "      <td>USA</td>\n",
       "      <td>1360</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>36450</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TexasA&amp;M</td>\n",
       "      <td>TX</td>\n",
       "      <td>USA</td>\n",
       "      <td>1075</td>\n",
       "      <td>49</td>\n",
       "      <td>67</td>\n",
       "      <td>25</td>\n",
       "      <td>8704</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>UCBerkeley</td>\n",
       "      <td>CA</td>\n",
       "      <td>USA</td>\n",
       "      <td>1240</td>\n",
       "      <td>95</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>15140</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>UChicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>USA</td>\n",
       "      <td>1290</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>38380</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>UMichigan</td>\n",
       "      <td>MI</td>\n",
       "      <td>USA</td>\n",
       "      <td>1180</td>\n",
       "      <td>65</td>\n",
       "      <td>68</td>\n",
       "      <td>16</td>\n",
       "      <td>15470</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>UPenn</td>\n",
       "      <td>PA</td>\n",
       "      <td>USA</td>\n",
       "      <td>1285</td>\n",
       "      <td>80</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>27553</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UVA</td>\n",
       "      <td>VA</td>\n",
       "      <td>USA</td>\n",
       "      <td>1225</td>\n",
       "      <td>77</td>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>13349</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>UWisconsin</td>\n",
       "      <td>WI</td>\n",
       "      <td>USA</td>\n",
       "      <td>1085</td>\n",
       "      <td>40</td>\n",
       "      <td>69</td>\n",
       "      <td>15</td>\n",
       "      <td>11857</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Yale</td>\n",
       "      <td>CT</td>\n",
       "      <td>USA</td>\n",
       "      <td>1375</td>\n",
       "      <td>95</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>43514</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Univ State Country   SAT  Top10  Accept  SFRatio  Expenses  \\\n",
       "0          Brown    RI     USA  1310     89      22       13     22704   \n",
       "1        CalTech    CA     USA  1415    100      25        6     63575   \n",
       "2            CMU    PA     USA  1260     62      59        9     25026   \n",
       "3       Columbia    NY     USA  1310     76      24       12     31510   \n",
       "4        Cornell    NY     USA  1280     83      33       13     21864   \n",
       "5      Dartmouth    NH     USA  1340     89      23       10     32162   \n",
       "6           Duke    NC     USA  1315     90      30       12     31585   \n",
       "7     Georgetown    DC     USA  1255     74      24       12     20126   \n",
       "8        Harvard    MA     USA  1400     91      14       11     39525   \n",
       "9   JohnsHopkins    MD     USA  1305     75      44        7     58691   \n",
       "10           MIT    MA     USA  1380     94      30       10     34870   \n",
       "11  Northwestern    IL     USA  1260     85      39       11     28052   \n",
       "12     NotreDame    IN     USA  1255     81      42       13     15122   \n",
       "13     PennState    PA     USA  1081     38      54       18     10185   \n",
       "14     Princeton    NJ     USA  1375     91      14        8     30220   \n",
       "15        Purdue    IN     USA  1005     28      90       19      9066   \n",
       "16      Stanford    CA     USA  1360     90      20       12     36450   \n",
       "17      TexasA&M    TX     USA  1075     49      67       25      8704   \n",
       "18    UCBerkeley    CA     USA  1240     95      40       17     15140   \n",
       "19      UChicago    IL     USA  1290     75      50       13     38380   \n",
       "20     UMichigan    MI     USA  1180     65      68       16     15470   \n",
       "21         UPenn    PA     USA  1285     80      36       11     27553   \n",
       "22           UVA    VA     USA  1225     77      44       14     13349   \n",
       "23    UWisconsin    WI     USA  1085     40      69       15     11857   \n",
       "24          Yale    CT     USA  1375     95      19       11     43514   \n",
       "\n",
       "    GradRate  \n",
       "0         94  \n",
       "1         81  \n",
       "2         72  \n",
       "3         88  \n",
       "4         90  \n",
       "5         95  \n",
       "6         95  \n",
       "7         92  \n",
       "8         97  \n",
       "9         87  \n",
       "10        91  \n",
       "11        89  \n",
       "12        94  \n",
       "13        80  \n",
       "14        95  \n",
       "15        69  \n",
       "16        93  \n",
       "17        67  \n",
       "18        78  \n",
       "19        87  \n",
       "20        85  \n",
       "21        90  \n",
       "22        92  \n",
       "23        71  \n",
       "24        96  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Univ1 = pd.read_excel(\"/content/University_Clustering.xlsx\")\n",
    "Univ1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "qPTtXbbTb-Hq",
    "outputId": "d174f437-bbe5-4cef-ec4b-3a391f66fdd6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>Top10</th>\n",
       "      <th>Accept</th>\n",
       "      <th>SFRatio</th>\n",
       "      <th>Expenses</th>\n",
       "      <th>GradRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.00000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1266.440000</td>\n",
       "      <td>76.480000</td>\n",
       "      <td>39.200000</td>\n",
       "      <td>12.72000</td>\n",
       "      <td>27388.000000</td>\n",
       "      <td>86.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>108.359771</td>\n",
       "      <td>19.433905</td>\n",
       "      <td>19.727308</td>\n",
       "      <td>4.06735</td>\n",
       "      <td>14424.883165</td>\n",
       "      <td>9.057778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1005.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>8704.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1240.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>15140.000000</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1285.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>27553.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1340.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>34870.000000</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1415.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>25.00000</td>\n",
       "      <td>63575.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SAT       Top10     Accept   SFRatio      Expenses   GradRate\n",
       "count    25.000000   25.000000  25.000000  25.00000     25.000000  25.000000\n",
       "mean   1266.440000   76.480000  39.200000  12.72000  27388.000000  86.720000\n",
       "std     108.359771   19.433905  19.727308   4.06735  14424.883165   9.057778\n",
       "min    1005.000000   28.000000  14.000000   6.00000   8704.000000  67.000000\n",
       "25%    1240.000000   74.000000  24.000000  11.00000  15140.000000  81.000000\n",
       "50%    1285.000000   81.000000  36.000000  12.00000  27553.000000  90.000000\n",
       "75%    1340.000000   90.000000  50.000000  14.00000  34870.000000  94.000000\n",
       "max    1415.000000  100.000000  90.000000  25.00000  63575.000000  97.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EDA\n",
    "Univ1.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5e5qR8rCc3h7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Univ</th>\n",
       "      <th>SAT</th>\n",
       "      <th>Top10</th>\n",
       "      <th>Accept</th>\n",
       "      <th>SFRatio</th>\n",
       "      <th>Expenses</th>\n",
       "      <th>GradRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brown</td>\n",
       "      <td>1310</td>\n",
       "      <td>89</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>22704</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CalTech</td>\n",
       "      <td>1415</td>\n",
       "      <td>100</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>63575</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMU</td>\n",
       "      <td>1260</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>25026</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Columbia</td>\n",
       "      <td>1310</td>\n",
       "      <td>76</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>31510</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cornell</td>\n",
       "      <td>1280</td>\n",
       "      <td>83</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>21864</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dartmouth</td>\n",
       "      <td>1340</td>\n",
       "      <td>89</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>32162</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Duke</td>\n",
       "      <td>1315</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>31585</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Georgetown</td>\n",
       "      <td>1255</td>\n",
       "      <td>74</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>20126</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Harvard</td>\n",
       "      <td>1400</td>\n",
       "      <td>91</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>39525</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JohnsHopkins</td>\n",
       "      <td>1305</td>\n",
       "      <td>75</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>58691</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MIT</td>\n",
       "      <td>1380</td>\n",
       "      <td>94</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>34870</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Northwestern</td>\n",
       "      <td>1260</td>\n",
       "      <td>85</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>28052</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NotreDame</td>\n",
       "      <td>1255</td>\n",
       "      <td>81</td>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>15122</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PennState</td>\n",
       "      <td>1081</td>\n",
       "      <td>38</td>\n",
       "      <td>54</td>\n",
       "      <td>18</td>\n",
       "      <td>10185</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Princeton</td>\n",
       "      <td>1375</td>\n",
       "      <td>91</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>30220</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Purdue</td>\n",
       "      <td>1005</td>\n",
       "      <td>28</td>\n",
       "      <td>90</td>\n",
       "      <td>19</td>\n",
       "      <td>9066</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stanford</td>\n",
       "      <td>1360</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>36450</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TexasA&amp;M</td>\n",
       "      <td>1075</td>\n",
       "      <td>49</td>\n",
       "      <td>67</td>\n",
       "      <td>25</td>\n",
       "      <td>8704</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>UCBerkeley</td>\n",
       "      <td>1240</td>\n",
       "      <td>95</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>15140</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>UChicago</td>\n",
       "      <td>1290</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>38380</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>UMichigan</td>\n",
       "      <td>1180</td>\n",
       "      <td>65</td>\n",
       "      <td>68</td>\n",
       "      <td>16</td>\n",
       "      <td>15470</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>UPenn</td>\n",
       "      <td>1285</td>\n",
       "      <td>80</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>27553</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UVA</td>\n",
       "      <td>1225</td>\n",
       "      <td>77</td>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>13349</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>UWisconsin</td>\n",
       "      <td>1085</td>\n",
       "      <td>40</td>\n",
       "      <td>69</td>\n",
       "      <td>15</td>\n",
       "      <td>11857</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Yale</td>\n",
       "      <td>1375</td>\n",
       "      <td>95</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>43514</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Univ   SAT  Top10  Accept  SFRatio  Expenses  GradRate\n",
       "0          Brown  1310     89      22       13     22704        94\n",
       "1        CalTech  1415    100      25        6     63575        81\n",
       "2            CMU  1260     62      59        9     25026        72\n",
       "3       Columbia  1310     76      24       12     31510        88\n",
       "4        Cornell  1280     83      33       13     21864        90\n",
       "5      Dartmouth  1340     89      23       10     32162        95\n",
       "6           Duke  1315     90      30       12     31585        95\n",
       "7     Georgetown  1255     74      24       12     20126        92\n",
       "8        Harvard  1400     91      14       11     39525        97\n",
       "9   JohnsHopkins  1305     75      44        7     58691        87\n",
       "10           MIT  1380     94      30       10     34870        91\n",
       "11  Northwestern  1260     85      39       11     28052        89\n",
       "12     NotreDame  1255     81      42       13     15122        94\n",
       "13     PennState  1081     38      54       18     10185        80\n",
       "14     Princeton  1375     91      14        8     30220        95\n",
       "15        Purdue  1005     28      90       19      9066        69\n",
       "16      Stanford  1360     90      20       12     36450        93\n",
       "17      TexasA&M  1075     49      67       25      8704        67\n",
       "18    UCBerkeley  1240     95      40       17     15140        78\n",
       "19      UChicago  1290     75      50       13     38380        87\n",
       "20     UMichigan  1180     65      68       16     15470        85\n",
       "21         UPenn  1285     80      36       11     27553        90\n",
       "22           UVA  1225     77      44       14     13349        92\n",
       "23    UWisconsin  1085     40      69       15     11857        71\n",
       "24          Yale  1375     95      19       11     43514        96"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Univ = Univ1.drop([\"State\",\"Country\"], axis = 1)\n",
    "Univ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Si5oaVZIcDG9"
   },
   "outputs": [],
   "source": [
    "# Normalization function \n",
    "def norm_func(i):\n",
    "    x = (i - i.min())\t/ (i.max() - i.min())\n",
    "    return (x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "DDIr3Y0ZcIiC",
    "outputId": "df379b9a-0f5b-40d6-f2b0-df35c91933de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>Top10</th>\n",
       "      <th>Accept</th>\n",
       "      <th>SFRatio</th>\n",
       "      <th>Expenses</th>\n",
       "      <th>GradRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.637659</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.331579</td>\n",
       "      <td>0.353684</td>\n",
       "      <td>0.340508</td>\n",
       "      <td>0.657333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.264292</td>\n",
       "      <td>0.269915</td>\n",
       "      <td>0.259570</td>\n",
       "      <td>0.214071</td>\n",
       "      <td>0.262887</td>\n",
       "      <td>0.301926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.573171</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.117293</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.343515</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.817073</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.476864</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             SAT      Top10     Accept    SFRatio   Expenses   GradRate\n",
       "count  25.000000  25.000000  25.000000  25.000000  25.000000  25.000000\n",
       "mean    0.637659   0.673333   0.331579   0.353684   0.340508   0.657333\n",
       "std     0.264292   0.269915   0.259570   0.214071   0.262887   0.301926\n",
       "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000\n",
       "25%     0.573171   0.638889   0.131579   0.263158   0.117293   0.466667\n",
       "50%     0.682927   0.736111   0.289474   0.315789   0.343515   0.766667\n",
       "75%     0.817073   0.861111   0.473684   0.421053   0.476864   0.900000\n",
       "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalized data frame (considering the numerical part of data)\n",
    "df_norm = norm_func(Univ.iloc[:, 1:])\n",
    "df_norm.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KrHyck2ufdKa"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import\tKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KMeans in module sklearn.cluster._kmeans:\n",
      "\n",
      "class KMeans(_BaseKMeans)\n",
      " |  KMeans(n_clusters=8, *, init='k-means++', n_init='warn', max_iter=300, tol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='lloyd')\n",
      " |  \n",
      " |  K-Means clustering.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <k_means>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  \n",
      " |  n_clusters : int, default=8\n",
      " |      The number of clusters to form as well as the number of\n",
      " |      centroids to generate.\n",
      " |  \n",
      " |  init : {'k-means++', 'random'}, callable or array-like of shape             (n_clusters, n_features), default='k-means++'\n",
      " |      Method for initialization:\n",
      " |  \n",
      " |      'k-means++' : selects initial cluster centroids using sampling based on\n",
      " |      an empirical probability distribution of the points' contribution to the\n",
      " |      overall inertia. This technique speeds up convergence. The algorithm\n",
      " |      implemented is \"greedy k-means++\". It differs from the vanilla k-means++\n",
      " |      by making several trials at each sampling step and choosing the best centroid\n",
      " |      among them.\n",
      " |  \n",
      " |      'random': choose `n_clusters` observations (rows) at random from data\n",
      " |      for the initial centroids.\n",
      " |  \n",
      " |      If an array is passed, it should be of shape (n_clusters, n_features)\n",
      " |      and gives the initial centers.\n",
      " |  \n",
      " |      If a callable is passed, it should take arguments X, n_clusters and a\n",
      " |      random state and return an initialization.\n",
      " |  \n",
      " |  n_init : 'auto' or int, default=10\n",
      " |      Number of times the k-means algorithm is run with different centroid\n",
      " |      seeds. The final results is the best output of `n_init` consecutive runs\n",
      " |      in terms of inertia. Several runs are recommended for sparse\n",
      " |      high-dimensional problems (see :ref:`kmeans_sparse_high_dim`).\n",
      " |  \n",
      " |      When `n_init='auto'`, the number of runs depends on the value of init:\n",
      " |      10 if using `init='random'`, 1 if using `init='k-means++'`.\n",
      " |  \n",
      " |      .. versionadded:: 1.2\n",
      " |         Added 'auto' option for `n_init`.\n",
      " |  \n",
      " |      .. versionchanged:: 1.4\n",
      " |         Default value for `n_init` will change from 10 to `'auto'` in version 1.4.\n",
      " |  \n",
      " |  max_iter : int, default=300\n",
      " |      Maximum number of iterations of the k-means algorithm for a\n",
      " |      single run.\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Relative tolerance with regards to Frobenius norm of the difference\n",
      " |      in the cluster centers of two consecutive iterations to declare\n",
      " |      convergence.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Verbosity mode.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Determines random number generation for centroid initialization. Use\n",
      " |      an int to make the randomness deterministic.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  copy_x : bool, default=True\n",
      " |      When pre-computing distances it is more numerically accurate to center\n",
      " |      the data first. If copy_x is True (default), then the original data is\n",
      " |      not modified. If False, the original data is modified, and put back\n",
      " |      before the function returns, but small numerical differences may be\n",
      " |      introduced by subtracting and then adding the data mean. Note that if\n",
      " |      the original data is not C-contiguous, a copy will be made even if\n",
      " |      copy_x is False. If the original data is sparse, but not in CSR format,\n",
      " |      a copy will be made even if copy_x is False.\n",
      " |  \n",
      " |  algorithm : {\"lloyd\", \"elkan\", \"auto\", \"full\"}, default=\"lloyd\"\n",
      " |      K-means algorithm to use. The classical EM-style algorithm is `\"lloyd\"`.\n",
      " |      The `\"elkan\"` variation can be more efficient on some datasets with\n",
      " |      well-defined clusters, by using the triangle inequality. However it's\n",
      " |      more memory intensive due to the allocation of an extra array of shape\n",
      " |      `(n_samples, n_clusters)`.\n",
      " |  \n",
      " |      `\"auto\"` and `\"full\"` are deprecated and they will be removed in\n",
      " |      Scikit-Learn 1.3. They are both aliases for `\"lloyd\"`.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |          Added Elkan algorithm\n",
      " |  \n",
      " |      .. versionchanged:: 1.1\n",
      " |          Renamed \"full\" to \"lloyd\", and deprecated \"auto\" and \"full\".\n",
      " |          Changed \"auto\" to use \"lloyd\" instead of \"elkan\".\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cluster_centers_ : ndarray of shape (n_clusters, n_features)\n",
      " |      Coordinates of cluster centers. If the algorithm stops before fully\n",
      " |      converging (see ``tol`` and ``max_iter``), these will not be\n",
      " |      consistent with ``labels_``.\n",
      " |  \n",
      " |  labels_ : ndarray of shape (n_samples,)\n",
      " |      Labels of each point\n",
      " |  \n",
      " |  inertia_ : float\n",
      " |      Sum of squared distances of samples to their closest cluster center,\n",
      " |      weighted by the sample weights if provided.\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      Number of iterations run.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  MiniBatchKMeans : Alternative online implementation that does incremental\n",
      " |      updates of the centers positions using mini-batches.\n",
      " |      For large scale learning (say n_samples > 10k) MiniBatchKMeans is\n",
      " |      probably much faster than the default batch implementation.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The k-means problem is solved using either Lloyd's or Elkan's algorithm.\n",
      " |  \n",
      " |  The average complexity is given by O(k n T), where n is the number of\n",
      " |  samples and T is the number of iteration.\n",
      " |  \n",
      " |  The worst case complexity is given by O(n^(k+2/p)) with\n",
      " |  n = n_samples, p = n_features.\n",
      " |  Refer to :doi:`\"How slow is the k-means method?\" D. Arthur and S. Vassilvitskii -\n",
      " |  SoCG2006.<10.1145/1137856.1137880>` for more details.\n",
      " |  \n",
      " |  In practice, the k-means algorithm is very fast (one of the fastest\n",
      " |  clustering algorithms available), but it falls in local minima. That's why\n",
      " |  it can be useful to restart it several times.\n",
      " |  \n",
      " |  If the algorithm stops before fully converging (because of ``tol`` or\n",
      " |  ``max_iter``), ``labels_`` and ``cluster_centers_`` will not be consistent,\n",
      " |  i.e. the ``cluster_centers_`` will not be the means of the points in each\n",
      " |  cluster. Also, the estimator will reassign ``labels_`` after the last\n",
      " |  iteration to make ``labels_`` consistent with ``predict`` on the training\n",
      " |  set.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  \n",
      " |  >>> from sklearn.cluster import KMeans\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[1, 2], [1, 4], [1, 0],\n",
      " |  ...               [10, 2], [10, 4], [10, 0]])\n",
      " |  >>> kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(X)\n",
      " |  >>> kmeans.labels_\n",
      " |  array([1, 1, 1, 0, 0, 0], dtype=int32)\n",
      " |  >>> kmeans.predict([[0, 0], [12, 3]])\n",
      " |  array([1, 0], dtype=int32)\n",
      " |  >>> kmeans.cluster_centers_\n",
      " |  array([[10.,  2.],\n",
      " |         [ 1.,  2.]])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KMeans\n",
      " |      _BaseKMeans\n",
      " |      sklearn.base.ClassNamePrefixFeaturesOutMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.utils._set_output._SetOutputMixin\n",
      " |      sklearn.base.ClusterMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_clusters=8, *, init='k-means++', n_init='warn', max_iter=300, tol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='lloyd')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None, sample_weight=None)\n",
      " |      Compute k-means clustering.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training instances to cluster. It must be noted that the data\n",
      " |          will be converted to C ordering, which will cause a memory\n",
      " |          copy if the given data is not C-contiguous.\n",
      " |          If a sparse matrix is passed, a copy will be made if it's not in\n",
      " |          CSR format.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |          Not used, present here for API consistency by convention.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight.\n",
      " |      \n",
      " |          .. versionadded:: 0.20\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _BaseKMeans:\n",
      " |  \n",
      " |  fit_predict(self, X, y=None, sample_weight=None)\n",
      " |      Compute cluster centers and predict cluster index for each sample.\n",
      " |      \n",
      " |      Convenience method; equivalent to calling fit(X) followed by\n",
      " |      predict(X).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          New data to transform.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |          Not used, present here for API consistency by convention.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : ndarray of shape (n_samples,)\n",
      " |          Index of the cluster each sample belongs to.\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, sample_weight=None)\n",
      " |      Compute clustering and transform X to cluster-distance space.\n",
      " |      \n",
      " |      Equivalent to fit(X).transform(X), but more efficiently implemented.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          New data to transform.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |          Not used, present here for API consistency by convention.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray of shape (n_samples, n_clusters)\n",
      " |          X transformed in the new space.\n",
      " |  \n",
      " |  predict(self, X, sample_weight=None)\n",
      " |      Predict the closest cluster each sample in X belongs to.\n",
      " |      \n",
      " |      In the vector quantization literature, `cluster_centers_` is called\n",
      " |      the code book and each value returned by `predict` is the index of\n",
      " |      the closest code in the code book.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          New data to predict.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : ndarray of shape (n_samples,)\n",
      " |          Index of the cluster each sample belongs to.\n",
      " |  \n",
      " |  score(self, X, y=None, sample_weight=None)\n",
      " |      Opposite of the value of X on the K-means objective.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          New data.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |          Not used, present here for API consistency by convention.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Opposite of the value of X on the K-means objective.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Transform X to a cluster-distance space.\n",
      " |      \n",
      " |      In the new space, each dimension is the distance to the cluster\n",
      " |      centers. Note that even if X is sparse, the array returned by\n",
      " |      `transform` will typically be dense.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          New data to transform.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray of shape (n_samples, n_clusters)\n",
      " |          X transformed in the new space.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassNamePrefixFeaturesOutMixin:\n",
      " |  \n",
      " |  get_feature_names_out(self, input_features=None)\n",
      " |      Get output feature names for transformation.\n",
      " |      \n",
      " |      The feature names out will prefixed by the lowercased class name. For\n",
      " |      example, if the transformer outputs 3 features, then the feature names\n",
      " |      out are: `[\"class_name0\", \"class_name1\", \"class_name2\"]`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_features : array-like of str or None, default=None\n",
      " |          Only used to validate feature names with the names seen in :meth:`fit`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_names_out : ndarray of str objects\n",
      " |          Transformed feature names.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassNamePrefixFeaturesOutMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |  \n",
      " |  set_output(self, *, transform=None)\n",
      " |      Set output container.\n",
      " |      \n",
      " |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      " |      for an example on how to use the API.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      transform : {\"default\", \"pandas\"}, default=None\n",
      " |          Configure output of `transform` and `fit_transform`.\n",
      " |      \n",
      " |          - `\"default\"`: Default output format of a transformer\n",
      " |          - `\"pandas\"`: DataFrame output\n",
      " |          - `None`: Transform configuration is unchanged\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |  \n",
      " |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs) from abc.ABCMeta\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(KMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "N933xDUncN6c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "###### scree plot or elbow curve ############\n",
    "TWSS = []\n",
    "k = list(range(2, 20))\n",
    "\n",
    "for i in k:\n",
    "    kmeans = KMeans(n_clusters = i)\n",
    "    kmeans.fit(df_norm)\n",
    "    TWSS.append(kmeans.inertia_)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "he9cNl79cQgi",
    "outputId": "0850648b-f34a-4f64-901a-6682d8f146f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.12345244239718,\n",
       " 2.9674741004843965,\n",
       " 2.2308047771916275,\n",
       " 1.6781326840746351,\n",
       " 1.4963462976080284,\n",
       " 1.2861248939505896,\n",
       " 1.051229310979934,\n",
       " 0.89142699726236,\n",
       " 0.6928143554292531,\n",
       " 0.5399459160057575,\n",
       " 0.4558954891182139,\n",
       " 0.3549317015074797,\n",
       " 0.28541899771970647,\n",
       " 0.21956882488379253,\n",
       " 0.1840513335813473,\n",
       " 0.1363531085930762,\n",
       " 0.09954096236544088,\n",
       " 0.07141711401777791]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TWSS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "kFYhosiEcSnA",
    "outputId": "78b0b11b-b31b-4a4e-d465-ccead2d19793"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'total_within_SS')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGxCAYAAACeKZf2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABO7UlEQVR4nO3de1yTdf8/8Nfk6AFQTGEICp4w8RiYoGEqKWmZRqaWeai+3VkeQrNMvU3LX2G3HdAszW4PqaWZoNmtmZYMNdFCwUgR7RYFcUSeQE05Xr8/PvemEza2se3axuv5eFwPtmufa3tvTnl5XZ+DQpIkCUREREROooHcBRARERFZEsMNERERORWGGyIiInIqDDdERETkVBhuiIiIyKkw3BAREZFTYbghIiIip8JwQ0RERE7FVe4C5FBVVYULFy7Ay8sLCoVC7nKIiIjICJIk4dq1awgICECDBvrPz9TLcHPhwgUEBQXJXQYRERGZIT8/H4GBgXofr5fhxsvLC4D4cLy9vWWuhoiIiIxRUlKCoKAg7e9xfepluNFcivL29ma4ISIicjC1dSlhh2IiIiJyKgw3RERE5FQYboiIiMipMNwQERGRU2G4ISIiIqfCcENEREROheGGiIiInArDDRERETkVhhsiIiJyKvVyhmKrqKwE9u8H1GpAqQSiowEXF7mrIiIiqncYbiwhORl45RXg/Pnb+wIDgSVLgLg4+eoiIiKqh3hZqq6Sk4GRI3WDDQAUFIj9ycny1EVERFRPMdzURWWlOGMjSdUf0+yLjxftiIiIyCYYbupi//7qZ2zuJElAfr5oR0RERDbBcFMXarVl2xEREVGdMdzUhVJp2XZERERUZww3dREdLUZFKRQ1P65QAEFBoh0RERHZBMNNXbi4iOHegP6Ak5jI+W6IiIhsiOGmruLigC1bgFatdPf7+Ij9nOeGiIjIphhuLCEuDjh7FkhJAZ59Vuzr1o3BhoiISAZ2E24SEhKgUCgQHx9vsF1qairCw8Ph6emJtm3bYsWKFbYpsDYuLkD//sDcueJ+WhpQUiJrSURERPWRXYSbX3/9FStXrkS3bt0MtsvNzcXQoUMRHR2NjIwMzJkzB9OmTUNSUpKNKjVCu3Ziq6gAVCq5qyEiIqp3ZA83169fx9ixY/H555+jWbNmBtuuWLECrVu3RmJiIu6991783//9H5577jm8//77NqrWSLGx4ucPP8hbBxERUT0ke7iZPHkyHnnkETz00EO1tk1LS8PgwYN19sXGxiI9PR3l5eV6jystLUVJSYnOZlUMN0RERLKRNdxs2rQJR48eRUJCglHtCwsL4efnp7PPz88PFRUVuHjxot7jEhIS4OPjo92CgoLqVHetBgwAXF2B//5XbERERGQzsoWb/Px8vPLKK9iwYQM8PT2NPk5x13wy0v8WqLx7/51mz56N4uJi7Zafn29e0cby8gL69hW3efaGiIjIpmQLN0eOHEFRURHCw8Ph6uoKV1dXpKamYunSpXB1dUVlDStp+/v7o7CwUGdfUVERXF1d0bx5c72v5eHhAW9vb53N6jSXzxhuiIiIbEq2cBMTE4OsrCxkZmZqt4iICIwdOxaZmZlwqWFW36ioKOzZs0dn3+7duxEREQE3NzdblW4cTb+bvXsBA/2BiIiIyLJkCzdeXl7o0qWLzta4cWM0b94cXbp0ASAuJ40fP157zKRJk3Du3DnMmDED2dnZWL16NVatWoWZM2fK9Tb069kTaNECuH5dzHlDRERENiH7aClD1Go18vLytPdDQkKwc+dOqFQq9OjRAwsXLsTSpUvxxBNPyFilHg0aAIMGidu8NEVERGQzCknTI7ceKSkpgY+PD4qLi63b/2bdOmDCBCA8HEhPt97rEBER1QPG/v626zM3Dk9z5uboUeCvv+SthYiIqJ5guLEmpVIsoClJwF0doYmIiMg6GG6sTTNqavdueesgIiKqJxhurO3OcFP/ujcRERHZHMONtT3wANCoEaBWA1lZcldDRETk9BhurM3DA+jfX9zmkHAiIiKrY7ixBa4STkREZDMMN7agWWdq/37gxg15ayEiInJyDDe2EBoKtG4NlJUB+/bJXQ0REZFTY7ixBYWCl6aIiIhshOHGVhhuiIiIbILhxlZiYgAXF+DkSeCOxUCJiIjIshhubKVpU6B3b3GbZ2+IiIishuHGlnhpioiIyOoYbmxJMyT8p5+Aigp5ayEiInJSDDe21KsX0KwZcPUq8OuvcldDRETklBhubMnFBXjoIXGbl6aIiIisguHG1tjvhoiIyKoYbmxNE25++QW4ckXeWoiIiJwQw42tBQYCnTsDVVXAjz/KXQ0REZHTYbiRg2bU1O7d8tZBRETkhBhu5HBnvxtJkrcWIiIiJ8NwI4d+/QAPDyA/XyzHQERERBbDcCOHRo1EwAE4aoqIiMjCGG7kwiHhREREVsFwIxdNuElNBW7dkrcWIiIiJ8JwI5ewMCAgALh5EzhwQO5qiIiInAbDjVwUittDwnlpioiIyGIYbuTEfjdEREQWx3Ajp0GDxBmcrCzgwgW5qyEiInIKsoab5cuXo1u3bvD29oa3tzeioqLw/fff622vUqmgUCiqbScdda6Y5s2BiAhxm7MVExERWYSs4SYwMBCLFi1Ceno60tPTMXDgQAwfPhzHjx83eFxOTg7UarV269Chg40qtgJemiIiIrIoWcPNsGHDMHToUHTs2BEdO3bEO++8gyZNmuDQoUMGj2vZsiX8/f21m4uLi40qtgJNp+I9e8RimkRERFQndtPnprKyEps2bcKNGzcQFRVlsG3Pnj2hVCoRExODlJSUWp+7tLQUJSUlOpvdiIwEvLyAS5eAo0flroaIiMjhyR5usrKy0KRJE3h4eGDSpEnYunUrOnfuXGNbpVKJlStXIikpCcnJyQgNDUVMTAz27dtn8DUSEhLg4+Oj3YKCgqzxVszj5gbExIjbvDRFRERUZwpJkndZ6rKyMuTl5eHq1atISkrCv//9b6SmpuoNOHcbNmwYFAoFtm/frrdNaWkpSktLtfdLSkoQFBSE4uJieHt71/k91NmKFcBLLwHR0UAtQY2IiKi+KikpgY+PT62/v2U/c+Pu7o727dsjIiICCQkJ6N69O5YsWWL08ZGRkTh9+rTBNh4eHtoRWZrNrmg6FaelAfZ0yYyIiMgByR5u7iZJks5ZltpkZGRAqVRasSIbCAkBOnQAKiqAvXvlroaIiMihucr54nPmzMGQIUMQFBSEa9euYdOmTVCpVNi1axcAYPbs2SgoKMC6desAAImJiQgODkZYWBjKysqwYcMGJCUlISkpSc63YRmDBwOnT4v5bkaMkLsaIiIihyVruPnzzz8xbtw4qNVq+Pj4oFu3bti1axcGDRoEAFCr1cjLy9O2Lysrw8yZM1FQUICGDRsiLCwMO3bswNChQ+V6C5YTGwt88gk7FRMREdWR7B2K5WBshySbun4d8PUFysvFGZz27eWuiIiIyK44TIdi+p8mTYC+fcVtnr0hIiIyG8ONPeFSDERERHXGcGNPNOEmJQUoK5O3FiIiIgfFcGNPuncHWrQQ/W/S0uSuhoiIyCEx3NiTBg1uL6TJS1NERERmYbixN+x3Q0REVCcMN/ZGc+bm6FGgqEjeWoiIiBwQw4298fMDevQQt/fskbUUIiIiR8RwY494aYqIiMhsDDf2SHNpavduoP5NIE1ERFQnDDf2qG9foFEj4M8/gd9+k7saIiIih8JwY488PIABA8RtXpoiIiIyCcONvWK/GyIiIrMw3NgrTbg5cAC4cUPeWoiIiBwIw4296tABCA4Wa0ypVHJXQ0RE5DAYbuyVQsGlGIiIiMzAcGPPNJemdu+Wtw4iIiIHwnBjz2JiABcXICcHOHdO7mqIiIgcAsONPfPxASIjxW1emiIiIjIKw42945BwIiIikzDc2DtNuPnpJ6CiQt5aiIiIHADDjb0LDwd8fYHiYuDwYbmrISIisnsMN/bOxQV46CFxm6OmiIiIasVw4wjY74aIiMhoDDeOQDOZ36+/Apcvy1sLERGRnWO4cQSBgUBYGFBVBfz4o9zVEBER2TWGG0fBS1NERERGYbhxFHeuMyVJ8tZCRERkxxhuHEW/foCnJ1BQAGRny10NERGR3WK4cRQNG4qAA/DSFBERkQGyhpvly5ejW7du8Pb2hre3N6KiovD9998bPCY1NRXh4eHw9PRE27ZtsWLFChtVawfY74aIiKhWsoabwMBALFq0COnp6UhPT8fAgQMxfPhwHD9+vMb2ubm5GDp0KKKjo5GRkYE5c+Zg2rRpSEpKsnHlMtGEm9RU4OZNeWshIiKyUwpJsq/eqb6+vli8eDGef/75ao/NmjUL27dvR/YdfU4mTZqEY8eOIS0tzejXKCkpgY+PD4qLi+Ht7W2Rum1CkoCgINHv5ocfbncyJiIiqgeM/f1tN31uKisrsWnTJty4cQNRUVE1tklLS8Pgu36hx8bGIj09HeXl5bYoU14Kxe1A8+9/Axs3AioVUFkpa1lERET2xFXuArKyshAVFYVbt26hSZMm2Lp1Kzp37lxj28LCQvj5+ens8/PzQ0VFBS5evAilUlnjcaWlpSgtLdXeLykpsdwbsLVmzcTPb74RGyAm+VuyBIiLk68uIiIiOyH7mZvQ0FBkZmbi0KFDeOmllzBhwgScOHFCb3uFQqFzX3NV7e79d0pISICPj492CwoKskzxtpacDHz0UfX9BQXAyJHicSIionpO9nDj7u6O9u3bIyIiAgkJCejevTuWLFlSY1t/f38UFhbq7CsqKoKrqyuaN2+u9zVmz56N4uJi7Zafn2/R92ATlZXAK6/UPIGfZl98PC9RERFRvSd7uLmbJEk6l5DuFBUVhT179ujs2717NyIiIuDm5qb3OT08PLTDzTWbw9m/Hzh/Xv/jkgTk54t2RERE9Zis4WbOnDnYv38/zp49i6ysLMydOxcqlQpjx44FIM64jB8/Xtt+0qRJOHfuHGbMmIHs7GysXr0aq1atwsyZM+V6C7ajVlu2HRERkZOStUPxn3/+iXHjxkGtVsPHxwfdunXDrl27MGjQIACAWq1GXl6etn1ISAh27tyJ6dOn45NPPkFAQACWLl2KJ554Qq63YDt6Okub3Y6IiMhJ2d08N7bgkPPcVFYCwcGi83BNf2QKhRg1lZsLuLjYvDwiIiJrc7h5bqgWLi5iuDcggkxNEhMZbIiIqN5juHEkcXHAli1Aq1a6+11dgc2bOc8NERERGG4cT1wccPYskJICrF4NNG4MVFSIVcOJiIiI4cYhubgA/fsDzz4LTJok9iUmylkRERGR3WC4cXRTpgANGgA//gjoWU2diIioPmG4cXTBwcDw4eL20qWylkJERGQPGG6cwSuviJ/r1wOXL8tbCxERkcwYbpxBv35Ajx7AzZvA55/LXQ0REZGsGG6cgUJx++zNJ5+I0VNERET1FMONsxgzBmjRQiyeuXWr3NUQERHJhuHGWXh6clg4ERERGG6cy0svAW5uwMGDQHq63NUQERHJguHGmSiVwKhR4rZmHSoiIqJ6huHG2Wg6Fn/9NaBWy1sLERGRDBhunE2vXkCfPkB5ObBihdzVEBER2RzDjTPSnL1ZsQK4dUveWoiIiGyM4cYZPf44EBgIFBUBmzbJXQ0REZFNMdw4Izc3YPJkcXvJEkCS5K2HiIjIhhhunNULLwANGwKZmcD+/XJXQ0REZDMmhZs//vgDR44c0dn3008/YcCAAbj//vvx7rvvWrQ4qoPmzYFnnhG3OSyciIjqEZPCzWuvvYZt27Zp7+fm5mLYsGFwd3dHVFQUEhISkMjZce2HpmPxtm3A2bNyVkJERGQzJoWb9PR0DB06VHv/yy+/RMeOHfHDDz9gyZIlSExMxNq1ay1dI5krLAx46CGgqkosqElERFQPmBRuLl68iMDAQO39lJQUDBs2THu/f//+OMszBPZFc/bm88+B69flrYWIiMgGTAo3vr6+UP9v1tuqqiqkp6ejd+/e2sfLysogcWSOfRk6FGjfHiguBtatk7saIiIiqzMp3Dz44INYuHAh8vPzkZiYiKqqKgwYMED7+IkTJxAcHGzpGqkuGjQApk4Vt5cuFZeoiIiInJhJ4eadd95BdnY2goODMWvWLPzrX/9C48aNtY+vX78eAwcOtHiRVEcTJwJeXkBODrB7t9zVEBERWZVCMvE6Unl5OU6cOIEWLVogICBA57Fjx44hMDAQzZs3t2iRllZSUgIfHx8UFxfD29tb7nJsY/p0IDERePhh4Pvv5a6GiIjIZMb+/jY53NSkoqICt27dQpMmTer6VDZRL8PNmTOi740kAdnZQKdOcldERERkEmN/f5t0WWrnzp1Yv369zr533nkHTZo0QdOmTTF48GBcuXLFvIrJutq2BTQj25YulbcWIiIiKzIp3Lz//vsoKSnR3j948CDefPNNzJs3D5s3b0Z+fj4WLlxo8SLJQjTDwr/4AmAIJSIiJ2VSuPn999/Rp08f7f0tW7Zg0KBBmDt3LuLi4vDBBx/gu+++s3iRZCEDBgBdugB//w2sWiV3NURERFZhUri5du2aTmfhAwcO6IyOCgsLw4ULF4x+voSEBPTq1QteXl5o2bIlRowYgZycHIPHqFQqKBSKatvJkydNeSv1k0Jx++zNsmVARYW89RAREVmBSeEmICAA2dnZAIDr16/j2LFj6Nu3r/bxS5cuoVGjRkY/X2pqKiZPnoxDhw5hz549qKiowODBg3Hjxo1aj83JyYFardZuHTp0MOWt1F9jx4pFNc+dA7Zvl7saIiIii3M1pfHIkSMRHx+POXPmYOfOnfD390dkZKT28fT0dISGhhr9fLt27dK5v2bNGrRs2RJHjhxBv379DB7bsmVLNG3a1JTyCQAaNgRefBF4912xWnhcnNwVERERWZRJZ27mz5+PiIgITJs2DZmZmdiwYQNcXFy0j2/cuFFnrSlTFRcXAxDLPNSmZ8+eUCqViImJQUpKisG2paWlKCkp0dnqtZdfBlxdgX37gIwMuashIiKyKIvMc6PPzz//jIiICHh4eNTaVpIkDB8+HFeuXMH+/fv1tsvJycG+ffsQHh6O0tJSrF+/HitWrIBKpdJ7tmfBggV46623qu2vV/Pc3O2pp4BNm4AJEwCu5E5ERA7AppP46ePt7Y3MzEy0bdu21raTJ0/Gjh07cODAAZ2Vx40xbNgwKBQKbNfTh6S0tBSlpaXa+yUlJQgKCqrf4ebQISAqCnB3B/LyAD8/uSsiIiIyyCqT+JnK2Nw0depUbN++HSkpKSYHGwCIjIzE6dOn9T7u4eEBb29vna3ei4wE7r8fKCsDPvtM7mqIiIgsxqrhpjaSJGHKlClITk7G3r17ERISYtbzZGRkQKlUWri6ekAzLHz5chFyiIiInIBJo6UsbfLkyfjqq6/w7bffwsvLC4WFhQAAHx8fNGzYEAAwe/ZsFBQUYN26dQCAxMREBAcHIywsDGVlZdiwYQOSkpKQlJQk2/twWCNHAq+9Bly4AGzeDDzzjNwVERER1ZmsZ26WL1+O4uJi9O/fH0qlUrt9/fXX2jZqtRp5eXna+2VlZZg5cya6deuG6OhoHDhwADt27EAchzSbzt1djJwCxIrh1ut+RUREZDN206HYlurlquD6/PUXEBQElJYCBw4Ad0zKSEREZE8cqkMxyahFCzFrMSAm9SMiInJwVg03165ds7uzNlQDTcfi5GQgP1/eWoiIiOrIrHDz559/Yty4cQgICICrqytcXFx0NnIw3boB/fsDlZXAJ5/IXQ0REVGdmDVaauLEicjLy8O8efOgVCqhUCgsXRfZ2iuvACoVsHIl8OabgAkLoBIREdkTs8LNgQMHsH//fvTo0cPC5ZBshg0DQkKA3FxgwwbgH/+QuyIiIiKzmHVZKigoiJ2FnY2LCzB1qri9ZAmHhRMRkcMyK9wkJibijTfewNmzZy1cDsnqueeAJk2AEyeAH3+UuxoiIiKzmBVuRo8eDZVKhXbt2sHLywu+vr46GzkoHx9g4kRxm8PCiYjIQZnV5yYxMdHCZZDdmDoVWLYM2LEDOH0a6NBB7oqIiIhMYtUZiu0VZyiuxSOPADt3iqCzdKnc1RAREQGwwgzFJSUlOrcNbeTg4uPFzzVrgOJiWUshIiIyldGXpZo1awa1Wo2WLVuiadOmNc5tI0kSFAoFKisrLVok2dhDDwGdO4uOxXPmAA88ACiVQHS0GFVFRERkx4wON3v37tV2Fk5JSbFaQWQHFAoRZE6cAD79VGwAEBgoOhpzBXYiIrJj7HPDPjfVJScDI0dWn+tGc7ZuyxYGHCIisjljf3+bHW6uXr2KX375BUVFRaiqqtJ5bPz48eY8pc0w3BhQWQkEBwPnz9f8uEIhzuDk5vISFRER2ZSxv7/NGgr+3XffYezYsbhx4wa8vLx0+t8oFAq7DzdkwP79+oMNIM7m5OeLdv3726wsIiIiY5k1id+rr76K5557DteuXcPVq1dx5coV7Xb58mVL10i2pFZbth0REZGNmRVuCgoKMG3aNDTiytHOR6m0bDsiIiIbMyvcxMbGIj093dK1kD2IjhZ9amoY6g9A7A8KEu2IiIjskNF9brZv3669/cgjj+C1117DiRMn0LVrV7i5uem0feyxxyxXIdmWi4sY7j1ypAgyd/c3lyQgMZGdiYmIyG4ZPVqqQQPjTvI4wiR+HC1lhORk4JVXqncudnUFTp4E2rWTpy4iIqq3LL78QlVVlVGbvQcbMlJcHHD2LJCSAnz1FbB3r5i5uKICmDlT7uqIiIj0MqvPzbp161BaWlptf1lZGdatW1fnoshOuLiI4d5PPQUMGHD7ctS2bcCPP8pcHBERUc3MCjfPPvssimtYUPHatWt49tln61wU2amwMODll8Xt+HhxFoeIiMjOmBVuNAtk3u38+fPw8fGpc1FkxxYsAHx9gePHgRUr5K6GiIioGpNmKO7ZsycUCgUUCgViYmLg6nr78MrKSuTm5uLhhx+2eJFkR3x9gYULgcmTgTffFJesmjeXuyoiIiItk8LNiBEjAACZmZmIjY1FkyZNtI+5u7sjODgYTzzxhEULJDv0j3+IszZZWcD8+cCyZXJXREREpGXWwplffPEFRo8eDU9PT2vUZHUcCm4Be/cCMTFAgwZAZibQtavcFRERkZOz+FDwO02YMMFhgw1ZyMCBYrh4VZXoXGze4vJEREQWZ3S48fX1xcWLFwEAzZo1g6+vr96N6onFiwEPD3EW59tv5a6GiIgIgAl9bj766CN4eXlpb9c0WspUCQkJSE5OxsmTJ9GwYUP06dMH7733HkJDQw0el5qaihkzZuD48eMICAjA66+/jkmTJtW5HjJR27bAq68C774rfj78MMAzekREJDOz+txYysMPP4wxY8agV69eqKiowNy5c5GVlYUTJ06gcePGNR6Tm5uLLl264IUXXsCLL76In3/+GS+//DI2btxodGdm9rmxoOvXgdBQ4MIFEXJmz5a7IiIiclLG/v42K9yMHTsW/fv3x4MPPoiOHTvWqdA7/fXXX2jZsiVSU1PRr1+/GtvMmjUL27dvR3Z2tnbfpEmTcOzYMaSlpRn1Ogw3FrZhAzBuHNC4MXDqFBAQIHdFRETkhKzaobhJkyb44IMP0KlTJwQEBOCpp57CihUrcPLkSbMLBqCd9dhQv520tDQMHjxYZ19sbCzS09NRXl5ep9cnMz39NBAZCdy4wTM3REQkO7PCzWeffYaTJ0/iwoUL+PDDD+Hj44MlS5YgLCwMSqXSrEIkScKMGTPwwAMPoEuXLnrbFRYWws/PT2efn58fKioqtB2e71ZaWoqSkhKdjSyoQQNgyRJxe9064PBheeshIqJ6zaxwo+Hl5YVmzZqhWbNmaNq0KVxdXeHv72/Wc02ZMgW//fYbNm7cWGvbuzsza66s6evknJCQAB8fH+0WFBRkVo1kwP33AxMmiNuvvCKGiBMREcnArHAza9YsREZG4p577sE///lPlJWVYfbs2fjzzz+RkZFh8vNNnToV27dvR0pKCgIDAw229ff3R2Fhoc6+oqIiuLq6ormeZQBmz56N4uJi7Zafn29yjWSEhASgSRNx5ubLL+WuhoiI6imTll/QWLx4MVq0aIH58+dj+PDhuPfee816cUmSMHXqVGzduhUqlQohISG1HhMVFYXvvvtOZ9/u3bsREREBNze3Go/x8PCAh4eHWTWSCZRKYO5c0e9m1ixgxAjgf9MHEBER2YpZZ24yMjIwd+5c/PLLL+jXrx/8/f0xevRoLF++XGcUU20mT56MDRs24KuvvoKXlxcKCwtRWFiImzdvatvMnj0b48eP196fNGkSzp07hxkzZiA7OxurV6/GqlWrMHPmTHPeClna9OlAu3aAWi3O5BAREdmYRea5OXbsGBITE7FhwwZUVVWhsrLSuBfX00dmzZo1mDhxIgBg4sSJOHv2LFQqlfbx1NRUTJ8+XTuJ36xZs0yaxI9Dwa3s22/FWRt3dyA7W0z2R0REVEdWnecGEGdvVCoVVCoV9u/fj5KSEvTo0QMDBgzA4sWLzS7cFhhurEySgMGDgR9/BB5/HEhOlrsiIiJyAlYNN82aNcP169fRvXt39O/fH/3790e/fv0cJigw3NjA778DPXoAlZUi5MTEyF0RERE5OGN/f5vVoXj9+vVGhZnz588jICAADRrUacQ5OaIuXYCXXgKWLROrhmdkAK5mfd2IiIhMYlbqePTRR40649G5c2ecPXvWnJcgZ/DWW4CvrziL89lncldDRET1hFVPqci4JifZA19fYOFCcXvePODSJXnrISKieoHXi8i6/vEPcYnqyhVgwQK5qyEionqA4Yasy9UVSEwUt5cvF5eoiIiIrIjhhqwvJkYMCa+sFJ2LebmSiIisyKrhRt8kfVQPvf++mNTvp5+A7dvlroaIiJwYOxSTbbRtC7z6qrg9YwZw65a89RARkdOyarg5ceIE2rRpY82XIEcyZ45YXPPMmdv9cIiIiCzM6BmK4+LijH7SZDufbp8zFMto/Xpg/HigcWPg1CkgIEDuioiIyEFYfIZiHx8fixRG9dzYscAnnwCHD4szOWvXyl0RERE5GYusCu5oeOZGZocPA5GRt2/ff7+89RARkUMw9vc3h4KT7fXuLS5NAcC0aUBVlbz1EBGRUzH7zM2WLVuwefNm5OXloaysTOexo0ePWqQ4a+GZGztw4QLQsSNw4wawbh0wbpzcFRERkZ2z6pmbpUuX4tlnn0XLli2RkZGB+++/H82bN8eZM2cwZMgQs4umeiQgAPjnP8XtWbOA69flrYeIiJyGWeHm008/xcqVK7Fs2TK4u7vj9ddfx549ezBt2jQUFxdbukZyVvHxYv4btRp45x1ApQI2bhQ/KytlLo6IiByVWeEmLy8Pffr0AQA0bNgQ165dAwCMGzcOGzdutFx15Nw8PYEPPhC3Fy0CBgwAnn5a/AwOBux8SgEiIrJPZoUbf39/XLp0CQDQpk0bHDp0CACQm5vLWYnJNPrO0BQUACNHMuAQEZHJzAo3AwcOxHfffQcAeP755zF9+nQMGjQIo0ePxuOPP27RAsmJaRbSrIkmJMfH8xIVERGZxKzRUlVVVaiqqoKrq5gDcPPmzThw4ADat2+PSZMmwd3d3eKFWhJHS9kJlUpcgqpNSgrQv7+1qyEiIjtn8RmK73T+/HkEBQVp748aNQqjRo2CJEnIz89H69atzXlaqm/Uasu2IyIigpmXpUJCQvDXX39V23/58mWEhITUuSiqJ5RK49rl5Ny+TEVERFQLs8KNJElQKBTV9l+/fh2enp51LorqiehoIDAQqOG7pOOtt4B+/YAjR2xTFxEROTSTLkvNmDEDAKBQKDBv3jw0atRI+1hlZSUOHz6MHj16WLRAcmIuLsCSJWJUlEKhe3ZGE3iefBL47jvgwAEgIgKYMAF4912uJk5ERHqZdOYmIyMDGRkZkCQJWVlZ2vsZGRk4efIkunfvjrVc5ZlMERcHbNkCtGqluz8wUOz/+mvg1CngmWfE/i++ADp0ABYuBP7+2/b1EhGR3TNrtNSzzz6LJUuWOOxII46WskOVlcD+/aLzsFIpLlm5uOi2+eUXMTQ8LU3cDwwUk/899RTQgGvAEhE5O2N/f5u9cKbG+fPnoVAo0Oru/3nbMYYbByZJwObNwOuvA3l5Yl/v3kBiIhAZKWtpRERkXVZdOLOqqgpvv/02fHx80KZNG7Ru3RpNmzbFwoULUVVVZXbRRLVSKIDRo4GTJ8V6VI0bA4cPA1FRYukGTeAhIqJ6y6xwM3fuXCxbtgyLFi1CRkYGjh49infffRcff/wx5s2bZ+kaiapr2BCYMwc4fRp47jkRejZuBEJDgXnzuMo4EVE9ZtZlqYCAAKxYsQKPPfaYzv5vv/0WL7/8MgoKCixWoDXwspQTysgApk8HUlPFfaVSjKoaP579cYiInIRVL0tdvnwZnTp1qra/U6dOuHz5stHPs2/fPgwbNgwBAQFQKBTYtm2bwfYqlQoKhaLadvLkSVPfAjmbnj3FMg1JSUDbtqJj8rPPAr16Afv23W5XWSmWfdi4UfzkulVERE7HrHDTvXt3LFu2rNr+ZcuWoXv37kY/z40bN/Q+lyE5OTlQq9XarUOHDiYdT05KoRBDy0+cABYvBry9gaNHgQcfFHPpLF8OBAeL9ayeflr8DA7myuNERE7GrMtSqampeOSRR9C6dWtERUVBoVDg4MGDyM/Px86dOxEdHW16IQoFtm7dihEjRuhto1KpMGDAAFy5cgVNmzY1+TU0eFmqnigqAubPB1auBPR1dNdMFrhliwhGRERkt6x6WSokJASnTp3C448/jqtXr+Ly5cuIi4tDTk4O2rRpY3bRxurZsyeUSiViYmKQkpJSa/vS0lKUlJTobFQPtGwpztYcOQJ4eNTcRpPt4+N5iYqIyEmYtSp4SEgI1Go13nnnHZ39ly5dQlBQECqt9EtCqVRi5cqVCA8PR2lpKdavX4+YmBioVCr069dP73EJCQl46623rFITOYCrV4HSUv2PSxKQny8mEezf31ZVERGRlZgVbvRdybL2wpmhoaEIDQ3V3o+KikJ+fj7ef/99g+Fm9uzZ2nWxAHFaKygoyGp1kp1Rqy3bjoiI7JrZC2e++eabdrFwZmRkJDZs2GCwjYeHBzz0XZYg56dUGtfO0NkdIiJyGCaFm4yMDADQLpzp7u6ufczd3R3du3fHzJkzLVuhETUpjf3lRfVTdLRYh6qgQHfl8bv94x/AhQvAa68Bbm62q4+IiCzKpHCj6bxrqYUzr1+/jj/++EN7Pzc3F5mZmfD19UXr1q0xe/ZsFBQUYN26dQCAxMREBAcHIywsDGVlZdiwYQOSkpKQlJRUpzrIybm4AEuWiOHgCoVuwNGMlurZUwwbnztXzJWzejVgwrQGRERkP8waLbVmzRqLDKFOT09Hz5490bNnTwDislfPnj3x5ptvAgDUajXy7lgrqKysDDNnzkS3bt0QHR2NAwcOYMeOHYjjEF6qTVycGO599wKvgYFif3o6sG4d0KyZCDkREWIYeVmZPPUSEZHZ6rwquCPiPDf1WGWlGBWlVou+ONHR4syORmEh8PLLwNat4n6XLsCaNSLsEBGRrIz9/c1ww3BDd5Mk4JtvgClTgL/+EmtTvfYasGABYMXRgEREZJhVJ/EjcmoKBTBqFHD8OPDUU2J24/feA3r0AA4elLs6IiKqBcMNkT4tWgBffQVs2yYuYeXkAA88IGYzvnFD7uqIiEgPhhui2gwfLs7iTJwoLlktWQJ06yZWISciIrvDcENkjGbNRMfi778HgoKAM2eAgQOBl14Crl2TuzoiIroDww2RKR5+GPj9d+DFF8X9FSvEiKoffpC3LiIi0mK4ITKVt7cINT/9BISEAHl5IvQ89xxw5crtdpWVgEoFbNwofnLVcSIim2C4ITLXwIFAVhYwbZoYYbVmDRAWBmzfDiQnA8HBwIABwNNPi5/BwWI/ERFZFee54Tw3ZAkHDgDPPw+cOqW/jWaphy1bxIzJRERkEs5zQ2RLDzwAZGYChhaO1fw/Ij6el6iIiKyI4YbIUho2BB55xHAbSQLy88USEEREZBUMN0SWpFZbth0REZmM4YbIkpRKy7YjIiKTMdwQWVJ0NBAYeLvzcE08PYHQUNvVRERUzzDcEFmSi4tYngHQH3Bu3QLuu0/Mk0NERBbHcENkaXFxYrh3q1a6+4OCgI8+Ajp3BgoLgUGDgLlzgYoKeeokInJSnOeG89yQtVRWilFRarXoYxMdLc7s/P23GA7++eeiXZ8+Yhbj1q1lLZeIyN4Z+/ub4YbhhuTy9dfAP/4BlJQATZsCq1cDjz8ud1VERHaLk/gR2bvRo4GMDOD++4GrV8XlrMmTRZ8cIiIyG8MNkZzathWXrl57Tdz/9FOgd2/g5El56yIicmAMN0Ryc3cH/vUv4PvvgRYtgN9+A8LDxUKc9e+qMRFRnTHcENmLhx8Gjh0DYmJEp+PnngOeeQa4dk3uyoiIHArDDZE9USqBH34A3nlHjKz66isxJ86RI3JXRkTkMBhuiOyNiwswZw6QmiqGh//xBxAVBSQm8jIVEZERGG6I7FXfvmI01eOPA+XlwPTpwGOPARcvyl0ZEZFdY7ghsme+vkBSEvDJJ4CHB/Cf/wDdu4uzOkREVCOGGyJ7p1AAL78MHD4sFty8cAEYOBBYsEAs3VBZCahUYpZjlUrcJyKqxzhDMWcoJkdy4wYwdaoYJg6IdaquXBFLPGgEBorFO+Pi5KmRiMhKOEMxkTNq3Fgs07BhA+DpCZw4oRtsAKCgABg5EkhOlqdGIiKZMdwQOaIxY8R6VDXRnIyNj+clKiKql2QNN/v27cOwYcMQEBAAhUKBbdu21XpMamoqwsPD4enpibZt22LFihXWL5TI3uzfDxQW6n9ckoD8fNGOiKiekTXc3LhxA927d8eyZcuMap+bm4uhQ4ciOjoaGRkZmDNnDqZNm4akpCQrV0pkZ+6+FKXPH39Ytw4iIjvkKueLDxkyBEOGDDG6/YoVK9C6dWskJiYCAO69916kp6fj/fffxxNPPGGlKonskFJpXLv4eOD8efFT32UsIiIn41B9btLS0jB48GCdfbGxsUhPT0d5eblMVRHJIDpajIpSKPS3cXMTo6veegsIDhZDx69etVGBRETycahwU1hYCD8/P519fn5+qKiowEUDs7aWlpaipKREZyNyaC4uYrg3UD3gKBRi++or4JtvgC5dgOJiEXLatAHmzxfDx4mInJRDhRsAUNz1D7lmmp67998pISEBPj4+2i0oKMiqNRLZRFwcsGUL0KqV7v7AQLF/5EixHTt2O+SUlABvvy3O5DDkEJGTcqhw4+/vj8K7RogUFRXB1dUVzZs313vc7NmzUVxcrN3y8/OtXSqRbcTFAWfPAikp4kxNSgqQm6s7gV+DBrdDzpYtQNeuDDlE5NQcKtxERUVhz549Ovt2796NiIgIuLm56T3Ow8MD3t7eOhuR03BxAfr3B556Svx0cam5XYMGwBNPAJmZDDlE5NRkDTfXr19HZmYmMjMzAYih3pmZmcjLywMgzriMHz9e237SpEk4d+4cZsyYgezsbKxevRqrVq3CzJkz5SifyDHVFnLefJMhh4gcmqxrS6lUKgwYMKDa/gkTJmDt2rWYOHEizp49C5VKpX0sNTUV06dPx/HjxxEQEIBZs2Zh0qRJJr0u15YiukNVFbB1q+hwnJUl9nl7A6+8AkyfDjRrdrttZaWYGFCtFsPRo6P1nykiIrIwY39/c+FMhhsiwVDIiY8XK46/8oqYN0eDi3QSkQ0x3BjAcENkQE0hp2FD4ObN6m01oxS3bGHAISKr46rgRGSeO/vkJCWJPjk1BRuAi3QSkV1iuCGimjVoIM7G/G+5E724SCcR2RmGGyIy7M8/jWtn7GKeRERWxnBDRIYZu0ingYk0iYhsieGGiAwzZpFOAJg8Gdi71zY1EREZwHBDRIbVtkgnADRtCvzxBxATA4wbBxQV2bREIqI7MdwQUe0MLdKZlCTWt5o8WYSdDRuATp2Azz8Xw8qJiGyM89xwnhsi49U2Q/EvvwAvviiGkQNAnz7AihViODkRUR1xEj8DGG6IrKiiAvj4Y2DePODGDcDVFXj1VbFmVaNGcldHRA6Mk/gRkTxcXcWaVNnZwIgRIuy89x4QFgbs3Cl3dURUDzDcEJF1BAWJZRy+/VbcPnsWeOQR4MkngQsX5K6OiJwYww0RWddjjwEnTohLUy4uomNyp07i0hWXbCAiK2C4ISLra9IEeP994MgRoHdv4No1YNo0IDISOHpU7uqIyMkw3BCR7XTvDvz8M/Dpp4CPD5CeDvTqJRbevHbtdrvKSkClAjZuFD95hoeITMDRUhwtRSSPwkLR8XjTJnG/VStg6VKxEGd8PHD+/O22gYFiIsG4OFlKJSL7wKHgBjDcENmR3buBl14CzpzR30YzE/KWLQw4RPUYh4ITkWMYPBj4/Xdg9mz9bTT/B4uP5yUqIqoVww0Rya9hQxFyDJEkID9fzJBMRGQAww0R2Qe12rLtiKjeYrghIvugVBrX7tdfgVu3rFsLETk0hhsisg/R0WJUlKbzsD4ffQS0bQt88AFw/bptaiMih8JwQ0T2wcVFDPcGqgcchUJszz8vlnJQq4GZM4E2bYC33gIuX7Z9vURktxhuiMh+xMWJ4d6tWunuDwwU+//9b+CPP4BVq4AOHUSoWbBAhJzXXxdz5xBRvcd5bjjPDZH9qawUo6LUatEXJzpanNm5u01SEvDuu8CxY2Kfh4c4u/Paa0BwsM3LJiLr4iR+BjDcEDkRSQJ27gTeeQdISxP7XFyAsWOBN94A7r1X3vqIyGI4iR8R1Q8KBfDII2LNqpQUYNAgcVZn3TogLAwYOZKLcxLVMww3ROQcFAqgf3+xnMMvvwAjRoizOklJQHg4MGRIzRMAcpFOIqfDcENEzqdXL2DrVrGswzPPiMtUu3YB/fqJ/ju7dongk5ws+uYMGAA8/bT4GRws9hORw2KfG/a5IXJ+Z84A//oXsGYNUFYm9oWEALm51dtykU4iu8U+N0REGm3bAitWiDAzY4ZYy6qmYANwkU4iJ2AX4ebTTz9FSEgIPD09ER4ejv0GFsZTqVRQKBTVtpMnT9qwYiJySAEBYmbjjRsNt+MinUQOTfZw8/XXXyM+Ph5z585FRkYGoqOjMWTIEOTl5Rk8LicnB2q1Wrt16NDBRhUTkcP7+2/j2s2ZIyYOPHvWquUQkWXJ3uemd+/euO+++7B8+XLtvnvvvRcjRoxAQkJCtfYqlQoDBgzAlStX0LRpU7Nek31uiOo5lUp0HjZF27ZATIzYBg4EWrSwSmlEpJ9D9LkpKyvDkSNHMHjwYJ39gwcPxsGDBw0e27NnTyiVSsTExCAlJcVg29LSUpSUlOhsRFSP1bZIp0IBtGwJ/POfQN++YrTVmTPA558DY8aIx3r0AF59VUwgaMwCnhxyTmQzsoabixcvorKyEn5+fjr7/fz8UKhnjRilUomVK1ciKSkJycnJCA0NRUxMDPbt26f3dRISEuDj46PdgoKCLPo+iMjB1LZIJwAsXw4sXAgcOABcuQL85z/A9OlA167i8WPHgA8/FBMINmsmAtOCBaKfjmZElgaHnBPZlKyXpS5cuIBWrVrh4MGDiIqK0u5/5513sH79eqM7CQ8bNgwKhQLbt2+v8fHS0lKUlpZq75eUlCAoKIiXpYjqu+Rk4JVXgPPnb+8LCgISEw0PAy8qAvbuBX76Cfjxx+p9cho3FnPqxMSI+6+9dnsUlgaHnBOZzNjLUq42rKmae+65By4uLtXO0hQVFVU7m2NIZGQkNmzYoPdxDw8PeHh4mF0nETmpuDhg+PDaF+m8W8uW4vLUmDHi/pkzIuhotosXge+/F5s+kiQCTny8qKG21yQio8l6Wcrd3R3h4eHYs2ePzv49e/agT58+Rj9PRkYGlEqlpcsjovrAxUUs2/DUU+KnOSGjbVvghReATZuAP/8EMjPFkPPevQ0fxyHnRFYh65kbAJgxYwbGjRuHiIgIREVFYeXKlcjLy8OkSZMAALNnz0ZBQQHWrVsHAEhMTERwcDDCwsJQVlaGDRs2ICkpCUlJSXK+DSIioUEDoHt3sSmVoo9Nbd57T5zF6dsXcJX9n2Uihyf736LRo0fj0qVLePvtt6FWq9GlSxfs3LkTbdq0AQCo1WqdOW/Kysowc+ZMFBQUoGHDhggLC8OOHTswdOhQud4CEVHNjD2jvGuX2O65Bxg2DHj8cbG6uaendesjclKyz3MjB85zQ0Q2UVkpRkUVFFTvUAyIszXNm4sVy3fsAC5fvv1Y48Zi/+OPixFZPj42K5vIXjnEPDdERE7NmCHnn30GrFsn+ur89BMwZYqYg+fGDTGSauxYMWFgbKxYH0utrv11OacO1XM8c8MzN0RkbaYOOZck4MgRYOtWsWVn335MoQAiI8UZnREjgLuXnqnptQIDRcjikHNycMb+/ma4YbghIluorDR9yLlGTg6wbZsIOocP6z4WFiaCzuOPi5XOn3ySc+qQ02K4MYDhhogcVkEB8O23IuykpAAVFbcfc3HRfwlKoRBncHJzOacOOSz2uSEickatWgEvvwzs3i1mSl6/XpyN8fAw3LeGc+pQPcJwQ0TkqJo1A555BkhKEh2TjbFoEfDVV2JW5fp34p7qCdnnuSEiIgv439xgtfrhB7EBYl6dyEix9e4N9Opl2pDzuvQjIrIi9rlhnxsicgbGzKnj6ytmTP7lFyAjo/rq5QoFcO+9uoEnLKzmwMJRWSQDdig2gOGGiJxScjIwcqS4fec/7TWNliotFWtgHTokRmAdOiQ6G9+tSRMgIkI38Bw8KF6Ho7LIxhhuDGC4ISKnZeqcOncqKroddA4dAn79Fbh2rXo7jsoimTDcGMBwQ0ROzVJ9YSorxQSCd57d+f1344798UcgJsb01yQygOHGAIYbIiIzrV4NPP987e3c3MTlrF69bm8dOohV083BzssE439/c7QUEREZr21b49qVlwNpaWLT8PYGwsNF0NEEnzZtqq+7dTd2XiYT8cwNz9wQERnPmFFZgYHArl3A0aOi3056uhiddfNm9fb33KN7hiciQpyZ0dB0kmbnZQIvSxnEcENEVAemjMrSqKgAjh8XQefXX8X222+6y0dotGolgk54uDg7c/FizXVYo/MyL3/ZNYYbAxhuiIjqqC6jsjRu3RIBRxN20tOBEydMnzk5JQXo39+0Y2rCy192j+HGAIYbIiILsMZZjuvXxeWs9HRxBujOPjv6NGok+gIFBYkwUtPPxo0NPwcvfzkEhhsDGG6IiByASgUMGGCZ52ratHro0dxWKoHYWNGPqCacu8ducLQUERE5tuhoESoMdV4OCAC+/x64cEFcTsrP1/15/jxQUgJcvSq2rCzT67hzRXVLXP7SYP8eq2G4ISIi++TiIvq7jBwpgkxNnZeXLgW6dhWbPiUlNQcfzc/c3JpHct1tzBjRybljR7GFhoqfAQGmz9/D/j1WxctSvCxFRGTfLNF52ZC6Xv5q1EhMUKgJPXcGn2bNqrdn/x6zsc+NAQw3REQOxpqXcIyZu0epBNatA/74Azh16vZ25kzNw9k17rlHN/S0bw9MnQr8+WfN7Tm83SCGGwMYboiISIc5c/cAYibms2dF0MnJ0Q0++jooG2P3bmDQIPOP13Cyy18MNwYw3BARUTWWvvx1/bo403Nn6ElLA/77X+OO9/cHWrcWNdT0s2VLw319nPDyF8ONAQw3RERUI2tfwrHk8HZ399vD2e8OP61aAUOHilFkNbHW8HYrf34MNwYw3BARkSyMXZvrl19Em/x8IC9P92d+vggtVVV1r+eLL4Bhw8Q8QLUtYFobG1wCY7gxgOGGiIhkY27/njuVl4uzI3cHH83PP/4Ql8WM5eYmLnO1bAn4+Rn+2aKFaF/Te7LyJTCGGwMYboiISFb2Mry9cWPgxg3Tn9/XVzfs7NqlP0xZ8BIYw40BDDdERCQ7uYe3awJHRQXw119ieHpRke7Pu/f99Zd4bnNYYIFTLr9ARERkz1xcLLucw93PXdvszomJop2Ly+21tmpTVQVcvqwber7/XswBVBu12qy3Yg4T54u2jk8//RQhISHw9PREeHg49u/fb7B9amoqwsPD4enpibZt22LFihU2qpSIiMhBxMWJvi6tWunuDww0vw9MgwZiYsKwMHHZa8wY4NlnjTtWqTT99cwke7j5+uuvER8fj7lz5yIjIwPR0dEYMmQI8vLyamyfm5uLoUOHIjo6GhkZGZgzZw6mTZuGpKQkG1dORERk5+LixCSDKSnAV1+Jn7m5lp3fRrPAqb7RVgqF6E8UHW2516yF7H1uevfujfvuuw/Lly/X7rv33nsxYsQIJCQkVGs/a9YsbN++HdnZ2dp9kyZNwrFjx5CWlmbUa7LPDRERkQVZYgSYEYz9/S3rmZuysjIcOXIEgwcP1tk/ePBgHDx4sMZj0tLSqrWPjY1Feno6ysvLrVYrERER6WGNS2B1IGuH4osXL6KyshJ+fn46+/38/FBYWFjjMYWFhTW2r6iowMWLF6Gs4ZpeaWkpSktLtfdLSkosUD0RERFpxcUBw4fbxSKddjFaSnHXdTpJkqrtq619Tfs1EhIS8NZbb9WxSiIiIjLImiPATCDrZal77rkHLi4u1c7SFBUVVTs7o+Hv719je1dXVzRv3rzGY2bPno3i4mLtlp+fb5k3QERERHZH1nDj7u6O8PBw7NmzR2f/nj170KdPnxqPiYqKqtZ+9+7diIiIgNvd00H/j4eHB7y9vXU2IiIick6yDwWfMWMG/v3vf2P16tXIzs7G9OnTkZeXh0mTJgEQZ13Gjx+vbT9p0iScO3cOM2bMQHZ2NlavXo1Vq1Zh5syZcr0FIiIisiOy97kZPXo0Ll26hLfffhtqtRpdunTBzp070aZNGwCAWq3WmfMmJCQEO3fuxPTp0/HJJ58gICAAS5cuxRNPPCHXWyAiIiI7Ivs8N3LgPDdERESOxyHmuSEiIiKyNIYbIiIicioMN0RERORUGG6IiIjIqcg+WkoOmj7UXIaBiIjIcWh+b9c2Fqpehptr164BAIKCgmSuhIiIiEx17do1+Pj46H28Xg4Fr6qqwoULF+Dl5WVwDStbKCkpQVBQEPLz8+v9sHR+FgI/B4Gfw238LAR+DkJ9/hwkScK1a9cQEBCABg3096ypl2duGjRogMDAQLnL0MFlIW7jZyHwcxD4OdzGz0Lg5yDU18/B0BkbDXYoJiIiIqfCcENEREROheFGZh4eHpg/fz48PDzkLkV2/CwEfg4CP4fb+FkI/BwEfg61q5cdiomIiMh58cwNERERORWGGyIiInIqDDdERETkVBhurCghIQG9evWCl5cXWrZsiREjRiAnJ8fgMSqVCgqFotp28uRJG1VtHQsWLKj2nvz9/Q0ek5qaivDwcHh6eqJt27ZYsWKFjaq1nuDg4Br/fCdPnlxje2f5Puzbtw/Dhg1DQEAAFAoFtm3bpvO4JElYsGABAgIC0LBhQ/Tv3x/Hjx+v9XmTkpLQuXNneHh4oHPnzti6dauV3oHlGPosysvLMWvWLHTt2hWNGzdGQEAAxo8fjwsXLhh8zrVr19b4Pbl165aV3435avtOTJw4sdr7iYyMrPV5He07UdvnUNOfq0KhwOLFi/U+pyN+HyyN4caKUlNTMXnyZBw6dAh79uxBRUUFBg8ejBs3btR6bE5ODtRqtXbr0KGDDSq2rrCwMJ33lJWVpbdtbm4uhg4diujoaGRkZGDOnDmYNm0akpKSbFix5f366686n8GePXsAAE8++aTB4xz9+3Djxg10794dy5Ytq/Hxf/3rX/jwww+xbNky/Prrr/D398egQYO0S6XUJC0tDaNHj8a4ceNw7NgxjBs3DqNGjcLhw4et9TYswtBn8ffff+Po0aOYN28ejh49iuTkZJw6dQqPPfZYrc/r7e2t8x1Rq9Xw9PS0xluwiNq+EwDw8MMP67yfnTt3GnxOR/xO1PY53P1nunr1aigUCjzxxBMGn9fRvg8WJ5HNFBUVSQCk1NRUvW1SUlIkANKVK1dsV5gNzJ8/X+revbvR7V9//XWpU6dOOvtefPFFKTIy0sKVyeuVV16R2rVrJ1VVVdX4uDN+HwBIW7du1d6vqqqS/P39pUWLFmn33bp1S/Lx8ZFWrFih93lGjRolPfzwwzr7YmNjpTFjxli8Zmu5+7OoyS+//CIBkM6dO6e3zZo1ayQfHx/LFmdDNX0OEyZMkIYPH27S8zj6d8KY78Pw4cOlgQMHGmzj6N8HS+CZGxsqLi4GAPj6+tbatmfPnlAqlYiJiUFKSoq1S7OJ06dPIyAgACEhIRgzZgzOnDmjt21aWhoGDx6ssy82Nhbp6ekoLy+3dqk2UVZWhg0bNuC5556rdY0zZ/w+aOTm5qKwsFDnz9vDwwMPPvggDh48qPc4fd8RQ8c4ouLiYigUCjRt2tRgu+vXr6NNmzYIDAzEo48+ioyMDNsUaEUqlQotW7ZEx44d8cILL6CoqMhge2f/Tvz555/YsWMHnn/++VrbOuP3wRQMNzYiSRJmzJiBBx54AF26dNHbTqlUYuXKlUhKSkJycjJCQ0MRExODffv22bBay+vduzfWrVuHH374AZ9//jkKCwvRp08fXLp0qcb2hYWF8PPz09nn5+eHiooKXLx40RYlW922bdtw9epVTJw4UW8bZ/0+3KmwsBAAavzz1jym7zhTj3E0t27dwhtvvIGnn37a4BpCnTp1wtq1a7F9+3Zs3LgRnp6e6Nu3L06fPm3Dai1ryJAh+PLLL7F371588MEH+PXXXzFw4ECUlpbqPcbZvxNffPEFvLy8EBcXZ7CdM34fTFUvF86Uw5QpU/Dbb7/hwIEDBtuFhoYiNDRUez8qKgr5+fl4//330a9fP2uXaTVDhgzR3u7atSuioqLQrl07fPHFF5gxY0aNx9x9NkP633yTcq/kbimrVq3CkCFDEBAQoLeNs34falLTn3dtf9bmHOMoysvLMWbMGFRVVeHTTz812DYyMlKns23fvn1x33334eOPP8bSpUutXapVjB49Wnu7S5cuiIiIQJs2bbBjxw6Dv9yd+TuxevVqjB07tta+M874fTAVz9zYwNSpU7F9+3akpKSYtRp5ZGSk0yXuxo0bo2vXrnrfl7+/f7X/bRUVFcHV1RXNmze3RYlWde7cOfz444/4v//7P5OPdbbvg2bUXE1/3nf/L/zu40w9xlGUl5dj1KhRyM3NxZ49e0xe+blBgwbo1auXU31PlEol2rRpY/A9OfN3Yv/+/cjJyTHr3wxn/D7UhuHGiiRJwpQpU5CcnIy9e/ciJCTErOfJyMiAUqm0cHXyKi0tRXZ2tt73FRUVpR1JpLF7925ERETAzc3NFiVa1Zo1a9CyZUs88sgjJh/rbN+HkJAQ+Pv76/x5l5WVITU1FX369NF7nL7viKFjHIEm2Jw+fRo//vijWWFekiRkZmY61ffk0qVLyM/PN/ienPU7AYgzveHh4ejevbvJxzrj96FW8vVldn4vvfSS5OPjI6lUKkmtVmu3v//+W9vmjTfekMaNG6e9/9FHH0lbt26VTp06Jf3+++/SG2+8IQGQkpKS5HgLFvPqq69KKpVKOnPmjHTo0CHp0Ucflby8vKSzZ89KklT9czhz5ozUqFEjafr06dKJEyekVatWSW5ubtKWLVvkegsWU1lZKbVu3VqaNWtWtcec9ftw7do1KSMjQ8rIyJAASB9++KGUkZGhHQG0aNEiycfHR0pOTpaysrKkp556SlIqlVJJSYn2OcaNGye98cYb2vs///yz5OLiIi1atEjKzs6WFi1aJLm6ukqHDh2y+fszhaHPory8XHrsscekwMBAKTMzU+ffjdLSUu1z3P1ZLFiwQNq1a5f03//+V8rIyJCeffZZydXVVTp8+LAcb9Eohj6Ha9euSa+++qp08OBBKTc3V0pJSZGioqKkVq1aOd13ora/G5IkScXFxVKjRo2k5cuX1/gczvB9sDSGGysCUOO2Zs0abZsJEyZIDz74oPb+e++9J7Vr107y9PSUmjVrJj3wwAPSjh07bF+8hY0ePVpSKpWSm5ubFBAQIMXFxUnHjx/XPn735yBJkqRSqaSePXtK7u7uUnBwsN6/2I7mhx9+kABIOTk51R5z1u+DZkj73duECRMkSRLDwefPny/5+/tLHh4eUr9+/aSsrCyd53jwwQe17TW++eYbKTQ0VHJzc5M6derkEKHP0GeRm5ur99+NlJQU7XPc/VnEx8dLrVu3ltzd3aUWLVpIgwcPlg4ePGj7N2cCQ5/D33//LQ0ePFhq0aKF5ObmJrVu3VqaMGGClJeXp/MczvCdqO3vhiRJ0meffSY1bNhQunr1ao3P4QzfB0vjquBERETkVNjnhoiIiJwKww0RERE5FYYbIiIicioMN0RERORUGG6IiIjIqTDcEBERkVNhuCEiIiKnwnBDREREToXhhojszrZt29C+fXu4uLggPj7eIs85ceJEjBgxwiLPRUT2jeGGiLQmTpwIhUKBRYsW6ezftm0bFAqFzep48cUXMXLkSOTn52PhwoW1tpckCStXrkTv3r3RpEkTNG3aFBEREUhMTMTff/9tlRqDg4ORmJholecmorphuCEiHZ6ennjvvfdw5coVWV7/+vXrKCoqQmxsLAICAuDl5VXrMePGjUN8fDyGDx+OlJQUZGZmYt68efj222+xe/duG1RtvrKyMrlLIHI6DDdEpOOhhx6Cv78/EhIS9LZJSkpCWFgYPDw8EBwcjA8++MDo579y5QrGjx+PZs2aoVGjRhgyZAhOnz4NAFCpVNowM3DgQCgUCqhUKoPPt3nzZnz55ZfYuHEj5syZg169eiE4OBjDhw/H3r17MWDAgBqPq+nMS48ePbBgwQLt/QULFqB169bw8PBAQEAApk2bBgDo378/zp07h+nTp0OhUOic1Tp48CD69euHhg0bIigoCNOmTcONGzd0Xvf//b//h4kTJ8LHxwcvvPACysrKMGXKFCiVSnh6eiI4ONjg509EhjHcEJEOFxcXvPvuu/j4449x/vz5ao8fOXIEo0aNwpgxY5CVlYUFCxZg3rx5WLt2rVHPP3HiRKSnp2P79u1IS0uDJEkYOnQoysvL0adPH+Tk5AAQAUqtVqNPnz4Gn+/LL79EaGgohg8fXu0xhUIBHx8fo+q625YtW/DRRx/hs88+w+nTp7Ft2zZ07doVAJCcnIzAwEC8/fbbUKvVUKvVAICsrCzExsYiLi4Ov/32G77++mscOHAAU6ZM0XnuxYsXo0uXLjhy5AjmzZuHpUuXYvv27di8eTNycnKwYcMGBAcHm1U3EQGuchdARPbn8ccfR48ePTB//nysWrVK57EPP/wQMTExmDdvHgCgY8eOOHHiBBYvXoyJEycafN7Tp09j+/bt+Pnnn7Wh5csvv0RQUBC2bduGJ598Ei1btgQA+Pr6wt/fv9ZaT58+jdDQUDPepWF5eXnw9/fHQw89BDc3N7Ru3Rr333+/tjYXFxd4eXnp1Lh48WI8/fTT2k7QHTp0wNKlS/Hggw9i+fLl8PT0BCDOSs2cOVPntTp06IAHHngACoUCbdq0sfj7IapPeOaGiGr03nvv4YsvvsCJEyd09mdnZ6Nv3746+/r27YvTp0+jsrLS4HNmZ2fD1dUVvXv31u5r3rw5QkNDkZ2dbVadkiRZpbPzk08+iZs3b6Jt27Z44YUXsHXrVlRUVBg85siRI1i7di2aNGmi3WJjY1FVVYXc3Fxtu4iICJ3jJk6ciMzMTISGhmLatGl230+IyN4x3BBRjfr164fY2FjMmTNHZ39NYUKSJKOeU1+7ugSUjh07mhWMGjRoUK2e8vJy7e2goCDk5OTgk08+QcOGDfHyyy+jX79+Om3uVlVVhRdffBGZmZna7dixYzh9+jTatWunbde4cWOd4+677z7k5uZi4cKFuHnzJkaNGoWRI0ea/J6ISGC4ISK9Fi1ahO+++w4HDx7U7uvcuTMOHDig0+7gwYPo2LEjXFxcDD5f586dUVFRgcOHD2v3Xbp0CadOncK9995rVo1PP/00Tp06hW+//bbaY5Ikobi4uMbjWrRooe0rAwAlJSU6Z1cAoGHDhnjsscewdOlSqFQqpKWlISsrCwDg7u5e7UzVfffdh+PHj6N9+/bVNnd3d4Pvw9vbG6NHj8bnn3+Or7/+GklJSbh8+bJRnwER6WK4ISK9unbtirFjx+Ljjz/W7nv11Vfx008/YeHChTh16hS++OILLFu2TKcPiT4dOnTA8OHD8cILL+DAgQM4duwYnnnmGbRq1arGDsHGGDVqFEaPHo2nnnoKCQkJSE9Px7lz5/Cf//wHDz30EFJSUmo8buDAgVi/fj3279+P33//HRMmTNAJZ2vXrsWqVavw+++/48yZM1i/fj0aNmyo7Q8THByMffv2oaCgABcvXgQAzJo1C2lpaZg8eTIyMzO1fYymTp1q8D189NFH2LRpE06ePIlTp07hm2++gb+/P5o2bWrWZ0JU3zHcEJFBCxcu1Ll8c99992Hz5s3YtGkTunTpgjfffBNvv/12rZ2JNdasWYPw8HA8+uijiIqKgiRJ2LlzJ9zc3MyqT6FQ4KuvvsKHH36IrVu34sEHH0S3bt2wYMECDB8+HLGxsTUeN3v2bPTr1w+PPvoohg4dihEjRuhcOmratCk+//xz9O3bF926dcNPP/2E7777Ds2bNwcAvP322zh79izatWuHFi1aAAC6deuG1NRUnD59GtHR0ejZsyfmzZsHpVJp8D00adIE7733HiIiItCrVy+cPXsWO3fuRIMG/CeayBwKydiL5UREREQOgP8tICIiIqfCcENEFrN//36dYdB3b+YYMmSI3ud79913LfwOiMgZ8LIUEVnMzZs3UVBQoPfx9u3bm/ycBQUFuHnzZo2P+fr6wtfX1+TnJCLnxnBDREREToWXpYiIiMipMNwQERGRU2G4ISIiIqfCcENEREROheGGiIiInArDDRERETkVhhsiIiJyKgw3RERE5FT+PyUJcHewC8WdAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Scree plot \n",
    "plt.plot(k, TWSS, 'ro-');\n",
    "plt.xlabel(\"No_of_Clusters\");\n",
    "plt.ylabel(\"total_within_SS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JkjCW-lUcVYh",
    "outputId": "14b9cee9-e088-4d55-aab0-d62a5ff96128"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\scs\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Selecting 5 clusters from the above scree plot which is the optimum number of clusters \n",
    "model = KMeans(n_clusters = 5)\n",
    "model.fit(df_norm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HrV7nG-DcYIU",
    "outputId": "0265e4c2-4ca8-4b13-89b1-7b4d42e83643"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 3, 0, 0, 2, 2, 0, 2, 4, 2, 0, 0, 1, 2, 1, 2, 1, 3, 0, 3, 0,\n",
       "       0, 1, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.labels_ # getting the labels of clusters assigned to each row \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "KSVhm25Tg3bs",
    "outputId": "c30c8408-03b5-4015-df96-0a3a610b1800"
   },
   "outputs": [],
   "source": [
    "Univ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "yXog1Q8cgznj"
   },
   "outputs": [],
   "source": [
    "mb = pd.Series(model.labels_)  # converting numpy array into pandas series object \n",
    "Univ['Clust'] = mb # creating a  new column and assigning it to new column \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "hAT3qH5wcbNN",
    "outputId": "a6fa02d1-88ac-4dd9-971d-6ddd6e806b6c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Univ</th>\n",
       "      <th>SAT</th>\n",
       "      <th>Top10</th>\n",
       "      <th>Accept</th>\n",
       "      <th>SFRatio</th>\n",
       "      <th>Expenses</th>\n",
       "      <th>GradRate</th>\n",
       "      <th>Clust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brown</td>\n",
       "      <td>1310</td>\n",
       "      <td>89</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>22704</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CalTech</td>\n",
       "      <td>1415</td>\n",
       "      <td>100</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>63575</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMU</td>\n",
       "      <td>1260</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>25026</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Columbia</td>\n",
       "      <td>1310</td>\n",
       "      <td>76</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>31510</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cornell</td>\n",
       "      <td>1280</td>\n",
       "      <td>83</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>21864</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Univ   SAT  Top10  Accept  SFRatio  Expenses  GradRate  Clust\n",
       "0     Brown  1310     89      22       13     22704        94      0\n",
       "1   CalTech  1415    100      25        6     63575        81      4\n",
       "2       CMU  1260     62      59        9     25026        72      3\n",
       "3  Columbia  1310     76      24       12     31510        88      0\n",
       "4   Cornell  1280     83      33       13     21864        90      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Univ.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "PuFrtdUlcdgM",
    "outputId": "f6469eac-3d82-42e0-8c24-5b04770154ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clust</th>\n",
       "      <th>Univ</th>\n",
       "      <th>SAT</th>\n",
       "      <th>Top10</th>\n",
       "      <th>Accept</th>\n",
       "      <th>SFRatio</th>\n",
       "      <th>Expenses</th>\n",
       "      <th>GradRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Brown</td>\n",
       "      <td>1310</td>\n",
       "      <td>89</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>22704</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>CalTech</td>\n",
       "      <td>1415</td>\n",
       "      <td>100</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>63575</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CMU</td>\n",
       "      <td>1260</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>25026</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Columbia</td>\n",
       "      <td>1310</td>\n",
       "      <td>76</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>31510</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Cornell</td>\n",
       "      <td>1280</td>\n",
       "      <td>83</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>21864</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clust      Univ   SAT  Top10  Accept  SFRatio  Expenses  GradRate\n",
       "0      0     Brown  1310     89      22       13     22704        94\n",
       "1      4   CalTech  1415    100      25        6     63575        81\n",
       "2      3       CMU  1260     62      59        9     25026        72\n",
       "3      0  Columbia  1310     76      24       12     31510        88\n",
       "4      0   Cornell  1280     83      33       13     21864        90"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Univ = Univ.iloc[:,[7,0,1,2,3,4,5,6]]\n",
    "Univ.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "DhUG7vf0cffS",
    "outputId": "29972232-73ce-4fcf-c95f-1d1376a0e7a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>Top10</th>\n",
       "      <th>Accept</th>\n",
       "      <th>SFRatio</th>\n",
       "      <th>Expenses</th>\n",
       "      <th>GradRate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clust</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1274.444444</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>34.888889</td>\n",
       "      <td>12.444444</td>\n",
       "      <td>24295.555556</td>\n",
       "      <td>90.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1061.500000</td>\n",
       "      <td>38.750000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>9953.000000</td>\n",
       "      <td>71.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1363.571429</td>\n",
       "      <td>91.428571</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>10.571429</td>\n",
       "      <td>35475.142857</td>\n",
       "      <td>94.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1226.666667</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>55.666667</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18545.333333</td>\n",
       "      <td>78.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1360.000000</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>61133.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SAT      Top10     Accept    SFRatio      Expenses   GradRate\n",
       "Clust                                                                       \n",
       "0      1274.444444  80.000000  34.888889  12.444444  24295.555556  90.666667\n",
       "1      1061.500000  38.750000  70.000000  19.250000   9953.000000  71.750000\n",
       "2      1363.571429  91.428571  21.428571  10.571429  35475.142857  94.571429\n",
       "3      1226.666667  74.000000  55.666667  14.000000  18545.333333  78.333333\n",
       "4      1360.000000  87.500000  34.500000   6.500000  61133.000000  84.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Univ.iloc[:, 2:].groupby(Univ.Clust).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "7wCaHFbnchyK",
    "outputId": "1d457cb5-b597-4c36-eca0-2f4046735203"
   },
   "outputs": [],
   "source": [
    "Univ.to_excel(\"Kmeans_university1.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\scs'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
